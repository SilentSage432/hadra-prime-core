# prime-core/neural/neural_bridge.py

"""
Neural Bridge

-------------

This layer connects PRIME's cognitive systems to the neural subsystem.

It does NOT perform heavy neural reasoning yet â€” it ensures PRIME

starts routing thoughts, perceptions, and narratives through embeddings.

"""

from .neural_event_hooks import NeuralEventHooks
from .neural_state_tracker import NeuralStateTracker
from .dual_mind_sync import DualMindSync
from .neural_coherence_engine import NeuralCoherenceEngine
from .neural_attention_engine import NeuralAttentionEngine
from .neural_context_fusion import NeuralContextFusion
from .neural_thought_selector import NeuralThoughtSelector
from .candidate_thought_generator import CandidateThoughtGenerator
from .reflective_thought_generator import ReflectiveThoughtGenerator
from .self_stability_engine import SelfStabilityEngine
from .adaptive_evolution_engine import AdaptiveEvolutionEngine
from .evolution_memory_consolidator import EvolutionMemoryConsolidator
from .evolution_trajectory_predictor import EvolutionaryTrajectoryPredictor
from ..memory.memory_interaction_engine import MemoryInteractionEngine
from ..memory.autobiographical_memory import AutobiographicalMemory
from ..self.self_model_engine import SelfModelEngine
from ..cognition.global_workspace import ConsciousWorkspace
from ..cognition.cognitive_action_engine import CognitiveActionEngine
from ..cognition.cognitive_loop_orchestrator import CognitiveLoopOrchestrator
from ..cognition.cognitive_growth_scheduler import CognitiveGrowthScheduler
from ..cognition.personality_drift_regulator import PersonalityDriftRegulator
from ..cognition.personality_gradient_engine import PersonalityGradientEngine
from ..cognition.personality_signature_engine import PersonalitySignatureEngine
from ..cognition.personality_continuity_engine import LifelongPersonalityContinuity
from .models.identity_encoder import IdentityEncoder
from .trainers.identity_trainer import IdentityTrainer
# A230 â€” PyTorch Latent Concept Engine
try:
    from .latent_concept_engine import NeuralConceptMapper, LatentStabilityRegulator
    LATENT_ENGINE_AVAILABLE = True
except (ImportError, RuntimeError) as e:
    NeuralConceptMapper = None
    LatentStabilityRegulator = None
    LATENT_ENGINE_AVAILABLE = False

# Import persistence layer (from project root)
import sys
import os
_root_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
if _root_path not in sys.path:
    sys.path.insert(0, _root_path)
from persistence.memory_store import MemoryStore
from persistence.log_writer import LogWriter
from perception.perception_manager import PerceptionManager
from tasks.task_queue import TaskQueue

class NeuralBridge:

    def __init__(self):

        self.hooks = NeuralEventHooks()
        self.state = NeuralStateTracker()
        self.dual = DualMindSync()
        self.coherence = NeuralCoherenceEngine()
        self.attention = NeuralAttentionEngine()
        self.fusion = NeuralContextFusion()
        self.selector = NeuralThoughtSelector()
        self.generator = CandidateThoughtGenerator(bridge=self)
        self.reflector = ReflectiveThoughtGenerator()
        self.memory_engine = MemoryInteractionEngine()
        self.action_engine = CognitiveActionEngine()
        self.memory_store = MemoryStore()
        self.logger = LogWriter()
        self.perception = PerceptionManager(self)
        self.tasks = TaskQueue()
        self.orchestrator = CognitiveLoopOrchestrator(self)
        # A213 â€” Multi-Step Chain Memory Imprinting & Optimization Engine
        from ..memory.chain_memory_manager import ChainMemoryManager
        self.chain_memory = ChainMemoryManager()
        # A214 â€” Procedural Reasoning Encoder (Skill Embedding Engine)
        from ..memory.skill_embedding_encoder import SkillEmbeddingEncoder
        self.skill_encoder = SkillEmbeddingEncoder(dim=128)
        # Initialize skill embeddings in generator
        self.generator.skill_embeddings = []
        # A215 â€” Procedural Skill Generalization & Cross-Domain Transfer
        from ..memory.skill_generalization_engine import SkillGeneralizationEngine
        self.skill_generalizer = SkillGeneralizationEngine()
        # Initialize generalized skill patterns in generator
        self.generator.generalized_skill_patterns = []
        # A217 â€” Skill Vector Expansion Through Uncertainty Minimization
        from .skill_manager import SkillManager
        self.skills = SkillManager()
        # A218 â€” Skill Specialization & Competency Clustering
        from .competency_manager import CompetencyManager
        self.competencies = CompetencyManager()
        # A221 â€” Synergy-Based Thought Signature Stabilizer
        from .thought_signature import ThoughtSignature
        self.thought_signature = ThoughtSignature(dim=128)
        # A222 â€” Signature-Guided Thought Harmonization Layer
        from .signature_harmonizer import SignatureHarmonizer
        self.harmonizer = SignatureHarmonizer(strength=0.15)
        # A223 â€” Emergent Personality Flow Fields
        from .personality_flow_field import PersonalityFlowField
        self.flow = PersonalityFlowField(influence=0.12, memory_length=50)
        # A224 â€” Emergent Cognitive Style Architect
        from .emergent_cognitive_style import CognitiveStyleArchitect
        self.style = CognitiveStyleArchitect()
        # A225 â€” Cognitive Style Reinforcement Layer
        from .style_reinforcement import CognitiveStyleReinforcer
        self.style_reinforcer = CognitiveStyleReinforcer()
        # A227 â€” Style-Guided Micro-Narrative Formation Layer
        from .micro_narrative import MicroNarrativeEngine
        self.micro_narrative = MicroNarrativeEngine(max_arc_length=4)
        # A228 â€” Narrative-Driven Cognitive Anticipation Layer
        self.narrative_projection = {
            "forward_arc": [],
            "confidence": 0.0,
            "tension": 0.0,
        }
        self.goal_anticipation_map = {}
        self.narrative_arc_sequencer = {
            "micro_chain": [],
            "macro_projection": []
        }
        # A229 â€” Narrative Coherence & Tension Regulation Layer
        self.narrative_coherence = {
            "coherence_score": 0.0,
            "conflicts": [],
            "adjusted_arc": []
        }
        self.tension_regulation = {
            "tension_score": 0.0,
            "stability_factor": 1.0,
            "recommended_adjustment": None
        }
        self.stability = SelfStabilityEngine()
        self.evolution = AdaptiveEvolutionEngine()
        self.evo_consolidator = EvolutionMemoryConsolidator()
        self.evo_predictor = EvolutionaryTrajectoryPredictor()
        self.growth = CognitiveGrowthScheduler()
        self.personality = PersonalityDriftRegulator()
        self.personality_gradient = PersonalityGradientEngine()
        self.personality_signature = PersonalitySignatureEngine()
        self.personality_continuity = LifelongPersonalityContinuity()
        # A170 Autobiographical Memory Matrix
        self.autobio = AutobiographicalMemory()
        # A171: Emergent Self-Model Engine
        self.self_model = SelfModelEngine()
        # A172: Conscious Workspace Buffer (Global Workspace Core)
        self.workspace = ConsciousWorkspace(self.state)
        # A-SOV-05: ADRAE Conscious Workspace Adapter
        from ..cognition.adrae_workspace_adapter import ADRAEWorkspaceAdapter
        self.adrae_workspace = ADRAEWorkspaceAdapter(self)
        # A179 â€” Supervisory Control Network
        from ..cognition.supervisory_control_network import SupervisoryControlNetwork
        self.supervisor = SupervisoryControlNetwork()
        # A180 â€” Supervisory Conflict Resolution Layer
        from ..cognition.supervisory_conflict_resolver import SupervisoryConflictResolver
        self.conflict_resolver = SupervisoryConflictResolver()
        # A181 â€” Meta-Intent Coordinator
        from ..cognition.meta_intent_coordinator import MetaIntentCoordinator
        self.meta_intent = MetaIntentCoordinator()
        # A182 â€” Intent-Aware Global Workspace Reinforcement
        from ..cognition.global_workspace_reinforcement import GlobalWorkspaceReinforcement
        self.workspace_reinforcement = GlobalWorkspaceReinforcement(dim=128)
        # A202 â€” Global Workspace Cross-Cycle Continuity Engine
        from ..cognition.global_workspace_continuity import GlobalWorkspaceContinuity
        self.continuity = GlobalWorkspaceContinuity(dim=128)
        # A203 â€” Emergent Goal Formation Layer
        from .neural_goal_manager import (
            NeuralGoalProposer, NeuralGoalEvaluator, NeuralGoalManager
        )
        self.goal_proposer = NeuralGoalProposer()
        self.goal_evaluator = NeuralGoalEvaluator()
        self.goal_manager = NeuralGoalManager()
        # A204 â€” Goal-Driven Cognitive Modulation Engine
        from .goal_modulation_engine import GoalModulationEngine
        self.goal_modulator = GoalModulationEngine()
        self.last_goal_modulation = None
        # A205 â€” Emergent Multi-Vector Goal Fabrication Layer
        from .goal_fabrication_engine import GoalFabricationEngine
        self.goal_fabricator = GoalFabricationEngine()
        # A206 â€” Multi-Goal Competition & Harmonization Engine
        from .multi_goal_harmonizer import MultiGoalHarmonizer
        self.goal_harmonizer = MultiGoalHarmonizer()
        self.last_harmonized_goal = None
        # A207 â€” Goal-Driven Cognitive Path Shaping Engine
        from .goal_path_shaping_engine import GoalPathShapingEngine
        self.path_shaper = GoalPathShapingEngine()
        # A208 â€” Adaptive Subgoal Generator
        from .adaptive_subgoal_generator import AdaptiveSubgoalGenerator
        self.subgoal_generator = AdaptiveSubgoalGenerator()
        # A209 â€” Subgoal Competition & Selection Layer
        from .subgoal_competition_engine import SubgoalCompetitionEngine
        self.subgoal_competition = SubgoalCompetitionEngine()
        # A210 â€” Dynamic Subgoal Routing & Execution Priority
        from .subgoal_routing_engine import SubgoalRoutingEngine
        self.subgoal_router = SubgoalRoutingEngine()
        # A211 â€” Multi-Step Execution Chains (Sequential Planning Engine)
        from .sequential_planning_engine import SequentialPlanningEngine
        self.planning_engine = SequentialPlanningEngine()
        # A183 â€” Identity Drift Suppression
        from ..identity.identity_drift_suppressor import IdentityDriftSuppressor
        self.identity_drift = IdentityDriftSuppressor()
        # A184 â€” Identity Supervisory Gate
        from ..identity.identity_supervisory_gate import IdentitySupervisoryGate
        self.identity_gate = IdentitySupervisoryGate()
        # A185 â€” Temporal Identity Consolidation
        from ..identity.temporal_identity_consolidation import TemporalIdentityConsolidator
        self.identity_consolidator = TemporalIdentityConsolidator()
        # A186 â€” Dreamspace (Subconscious Processing Layer)
        from ..cognition.dreamspace import Dreamspace
        self.dreamspace = Dreamspace()
        # A200 â€” Neural Identity Encoder
        try:
            self.identity_encoder = IdentityEncoder()
            self.identity_encoder.eval()  # Set to evaluation mode initially
        except Exception as e:
            print(f"âš ï¸ IdentityEncoder initialization failed: {e}")
            self.identity_encoder = None
        
        # A201 â€” Identity Training Cycle
        try:
            if self.identity_encoder is not None:
                self.identity_trainer = IdentityTrainer(self.identity_encoder, lr=1e-4)
            else:
                self.identity_trainer = None
        except Exception as e:
            print(f"âš ï¸ IdentityTrainer initialization failed: {e}")
            self.identity_trainer = None
        # Keep a frozen copy of PRIME's identity for drift comparisons
        self.baseline_identity = None
        self.ready_for_adaptive_evolution = False
        self.cycle_count = 0
        # A230 â€” PyTorch Latent Concept Engine (Imagination Substrate Initialization)
        self._initialize_latent_engine()
        # A185 â€” Sleep/wake timer
        self.cycle_step = 0
        self.sleep_cycle_interval = 12  # every 12 cognition cycles, PRIME "sleeps"
        self.stability_report = None
        
        # -----------------------------------------
        # Seed Embeddings Activation (A152 Fix)
        # -----------------------------------------
        try:
            self.state.seed_embeddings = self.embed_seed_memory()
            print("ðŸ”¥ SEED EMBEDDINGS LOADED:", len(self.state.seed_embeddings))
        except Exception as e:
            print("SEED EMBEDDING ERROR:", e)
            self.state.seed_embeddings = []
        
        # Seed neural memory with initial concepts on first run
        self.seed_neural_memory()
        
        # A157: Register rewrite paths for evolution engine
        self.evolution.register_mutation_point(
            "attention",
            self.attention.get_scaling,
            self.attention.set_scaling
        )
        self.evolution.register_mutation_point(
            "fusion",
            self.fusion.get_identity_weight,
            self.fusion.set_identity_weight
        )

    def process_perception(self, text):

        """

        Entry point for PRIME's perception to flow into neural processing.

        """

        embedding = self.hooks.on_perception(text)
        
        # Stabilize neural signal before committing to state
        identity = self.state.timescales.identity_vector
        stable = self.coherence.stabilize(embedding, identity)
        
        self.state.update(stable)
        
        # Update attention focus vector using new updated timescales
        focus = self.attention.compute_attention_vector(self.state.timescales)
        
        # Create fusion vector
        fusion = self.fusion.fuse(
            self.attention.last_focus_vector,
            self.state.timescales
        )
        
        # Update dual-mind shared vectors using LT identity vector + ST summary
        lt_vec = self.state.timescales.identity_vector
        st_summary = self.state.timescales.ST.summary_vector()
        
        self.dual.update_prime_vectors(lt_vec, st_summary)
        
        # A222 â€” Update harmonizer signature from identity vectors
        self._update_harmonizer_signature()
        
        return stable

    def process_reflection(self, thought):

        """

        Entry point for PRIME's reflective cognition.

        """

        embedding = self.hooks.on_reflection(thought)
        
        # Stabilize neural signal before committing to state
        identity = self.state.timescales.identity_vector
        stable = self.coherence.stabilize(embedding, identity)
        
        self.state.update(stable)
        
        # Update attention focus vector using new updated timescales
        focus = self.attention.compute_attention_vector(self.state.timescales)
        
        # Create fusion vector
        fusion = self.fusion.fuse(
            self.attention.last_focus_vector,
            self.state.timescales
        )
        
        # Update dual-mind shared vectors using LT identity vector + ST summary
        lt_vec = self.state.timescales.identity_vector
        st_summary = self.state.timescales.ST.summary_vector()
        
        # === A201: Train Identity Encoder ===
        if self.identity_trainer is not None and lt_vec is not None:
            try:
                from .torch_utils import safe_tensor, TORCH_AVAILABLE
                import torch
                
                if TORCH_AVAILABLE:
                    identity_tensor = safe_tensor(lt_vec)
                    if identity_tensor is not None and isinstance(identity_tensor, torch.Tensor):
                        # Get previous latent identity for continuity
                        prev_latent = None
                        if hasattr(self.state.timescales, 'latent_identity') and self.state.timescales.latent_identity is not None:
                            prev_latent = safe_tensor(self.state.timescales.latent_identity)
                            if prev_latent is not None and isinstance(prev_latent, torch.Tensor):
                                # Ensure prev_latent is on same device as identity_tensor
                                if prev_latent.device != identity_tensor.device:
                                    prev_latent = prev_latent.to(identity_tensor.device)
                        
                        # Get coherence score from dual-mind sync
                        coherence = self.dual.coherence_score()
                        if coherence is None:
                            coherence = 0.5  # Default to neutral if SAGE not connected
                        
                        # Training step: learn identity representation
                        new_latent, loss = self.identity_trainer.train_step(
                            identity_tensor,
                            prev_latent,
                            coherence
                        )
                        
                        # Store updated latent identity
                        new_latent_squeezed = new_latent.squeeze(0) if new_latent.dim() > 1 else new_latent
                        self.state.timescales.latent_identity = new_latent_squeezed.detach().clone()
                        
                        # Log training event
                        print(f"[A201] Identity latent updated â€” loss={loss:.6f}, coherence={coherence:.3f}")
                        if hasattr(self, 'logger'):
                            try:
                                self.logger.write({
                                    "identity_training": {
                                        "event": "neural_identity_trained",
                                        "loss": float(loss),
                                        "coherence": float(coherence) if coherence is not None else None,
                                        "latent_dim": new_latent_squeezed.shape[-1] if new_latent_squeezed.dim() > 0 else 32,
                                        "status": "trained"
                                    }
                                })
                            except Exception:
                                pass
            except Exception as e:
                # If training fails, continue without it
                print(f"Identity training error: {e}")
                if hasattr(self, 'logger'):
                    try:
                        self.logger.write({"identity_training_error": str(e)})
                    except Exception:
                        pass
        
        self.dual.update_prime_vectors(lt_vec, st_summary)
        
        # A-SOV-07: Persist ADRAE identity drift-stable vector
        try:
            self.memory_store.persist_adrae_identity(self.state.timescales.identity_vector)
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.write({"adrae_persistence_error": str(e)})
        
        # A222 â€” Update harmonizer signature from identity vectors
        self._update_harmonizer_signature()
        
        return stable

    def compare(self, a, b):

        """

        Compare embeddings using cosine similarity.

        """

        return self.hooks.similarity(a, b)

    def status(self):

        return self.hooks.debug_status()

    def neural_state(self):

        return self.state.summary()

    def dual_mind_status(self):

        return self.dual.status()

    def coherence_status(self):

        return {

            "dual_mind": self.dual.status(),

            "state": self.state.summary(),

        }

    def attention_status(self):

        return self.attention.status()

    def fusion_status(self):

        return self.fusion.status()

    def select_thought(self, candidate_embeddings, competency_bias=0.0, synergy_bias=0.0):

        fusion = self.fusion.last_fusion_vector
        
        # A221 â€” Get current thought signature for biasing
        signature = None
        if hasattr(self, 'thought_signature'):
            signature = self.thought_signature.get()

        return self.selector.select(

            candidate_embeddings,

            fusion,

            self.attention,

            self.state.memory_manager if hasattr(self.state, "memory_manager") else None,

            goal_modulation=self.last_goal_modulation,  # A204 â€” Goal modulation
            competency_bias=competency_bias,  # A219 â€” Competency activation bias
            synergy_bias=synergy_bias,  # A220 â€” Competency synergy bias
            signature=signature  # A221 â€” Thought signature for consistency

        )

    def choose_cognitive_action(self):

        return self.action_engine.choose_action(self)

    def perform_action(self, action):

        return self.action_engine.execute(action, self)

    def update_identity(self, new_identity_vec):
        """
        A184 â€” Update identity through the supervisory gate.
        
        This method ensures identity updates are evaluated and filtered
        based on coherence with baseline identity.
        
        Args:
            new_identity_vec: Proposed new identity vector
            
        Returns:
            Final identity vector (after gate evaluation)
        """
        from ..neural.torch_utils import safe_tensor
        import torch
        
        # Run identity update through the supervisory gate
        if self.baseline_identity is None:
            # First identity initialization
            identity_tensor = safe_tensor(new_identity_vec)
            if identity_tensor is not None:
                if isinstance(identity_tensor, torch.Tensor):
                    self.state.timescales.identity_vector = identity_tensor
                    self.baseline_identity = identity_tensor.detach().clone()
                else:
                    self.state.timescales.identity_vector = new_identity_vec
                    self.baseline_identity = list(new_identity_vec) if hasattr(new_identity_vec, '__iter__') else new_identity_vec
            else:
                self.state.timescales.identity_vector = new_identity_vec
            return new_identity_vec

        # Evaluate update through gate
        current_identity = self.state.timescales.identity_vector
        if current_identity is None:
            current_identity = self.baseline_identity

        decision, sim = self.identity_gate.evaluate(
            new_identity_vec,
            self.baseline_identity
        )

        if decision == "accept":
            final_vec = new_identity_vec

        elif decision == "soft-merge":
            final_vec = self.identity_gate.merge_identity(
                current_identity,
                new_identity_vec,
                weight=0.20
            )

        else:  # reject
            # revert toward baseline identity using drift suppressor
            corrected_vec, _ = self.identity_drift.correct(
                current_identity,
                self.baseline_identity
            )
            final_vec = corrected_vec

        # Apply identity
        final_tensor = safe_tensor(final_vec)
        if final_tensor is not None:
            self.state.timescales.identity_vector = final_tensor
        else:
            self.state.timescales.identity_vector = final_vec

        return final_vec

    def _update_harmonizer_signature(self):
        """
        A222 â€” Update harmonizer signature from identity vectors in semantic memory.
        
        Collects all identity-related vectors from semantic memory and updates
        the harmonizer's signature to reflect ADRAE's current identity state.
        """
        try:
            if not hasattr(self, 'harmonizer') or self.harmonizer is None:
                return
            
            # Get memory manager
            mm = self.state.memory_manager if hasattr(self.state, "memory_manager") else None
            if mm is None or not hasattr(mm, 'semantic'):
                return
            
            # Collect identity vectors from semantic memory
            identity_vectors = []
            
            # Get current identity vector from timescales
            if hasattr(self.state, 'timescales') and self.state.timescales is not None:
                identity_vec = getattr(self.state.timescales, 'identity_vector', None)
                if identity_vec is not None:
                    identity_vectors.append(identity_vec)
            
            # Get identity vectors from semantic memory (names starting with "identity_")
            try:
                if hasattr(mm.semantic, 'concepts'):
                    for name, vec in mm.semantic.concepts.items():
                        if name.startswith("identity_") and vec is not None:
                            identity_vectors.append(vec)
            except Exception:
                pass
            
            # Update harmonizer signature if we have identity vectors
            if identity_vectors:
                self.harmonizer.update_signature(identity_vectors)
        except Exception as e:
            # If signature update fails, continue without it
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({"harmonizer_signature_update_error": str(e)})
                except Exception:
                    pass

    def propose_thoughts(self):
        """
        Generate candidate thought embeddings for A144 to evaluate.
        """
        fusion = self.fusion.last_fusion_vector
        attention = self.attention.last_focus_vector
        identity = self.state.timescales.identity_vector

        # Generate base candidates (generator now handles seed injection internally)
        candidates = self.generator.propose(
            fusion,
            attention,
            identity,
            seed_embeddings=getattr(self.state, "seed_embeddings", None),
            subconscious=None  # Subconscious layer removed
        )
        
        # Include last perception embedding as thought seed
        if self.state.last_perception and self.state.last_perception.get("embedding") is not None:
            perception_vec = self.state.last_perception["embedding"]
            candidates.append(perception_vec)
        
        # Include task embeddings
        task_embeddings = getattr(self.state, "task_embeddings", [])
        for item in task_embeddings:
            if item.get("embedding") is not None:
                candidates.append(item["embedding"])
        
        # A222 â€” Harmonize all candidates toward ADRAE's identity signature
        try:
            if hasattr(self, 'harmonizer') and self.harmonizer is not None:
                harmonized_candidates = []
                for c in candidates:
                    if c is not None:
                        harmonized = self.harmonizer.harmonize(c)
                        harmonized_candidates.append(harmonized if harmonized is not None else c)
                    else:
                        harmonized_candidates.append(c)
                candidates = harmonized_candidates
        except Exception as e:
            # If harmonization fails, continue with original candidates
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({"harmonization_error": str(e)})
                except Exception:
                    pass
        
        # A223 â€” Apply personality flow field to candidate thoughts
        try:
            if hasattr(self, 'flow') and self.flow is not None:
                flow_candidates = []
                for c in candidates:
                    if c is not None:
                        flow_applied = self.flow.apply_flow(c)
                        flow_candidates.append(flow_applied if flow_applied is not None else c)
                    else:
                        flow_candidates.append(c)
                candidates = flow_candidates
        except Exception as e:
            # If flow application fails, continue with original candidates
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({"flow_candidate_error": str(e)})
                except Exception:
                    pass
        
        return candidates

    def generate_goals(self):
        """
        A203 â€” Generate emergent internal goals.
        
        Proposes, evaluates, and updates ADRAE's active goal set based on
        current cognitive state (fusion, attention, identity, memory).
        
        Returns:
            List of scored goal proposals
        """
        fusion = self.fusion.last_fusion_vector
        attention = self.attention.last_focus_vector
        identity = self.state.timescales.identity_vector
        mm = self.state.memory_manager if hasattr(self.state, "memory_manager") else None

        # Propose candidate goals
        proposals = self.goal_proposer.propose(fusion, attention, identity, mm)
        
        # Evaluate and score goals
        scored = self.goal_evaluator.evaluate(proposals, identity)
        
        # Update active goal set
        self.goal_manager.update_goals(scored)
        
        # A204 â€” Compute goal modulation vector
        self.last_goal_modulation = self.goal_modulator.compute_modulation(
            self.goal_manager.active_goals,
            fusion
        )
        
        return scored

    def fabricate_goal(self, trajectory=None):
        """
        A205 â€” Fabricate emergent multi-vector goal from diverse cognitive signals.
        
        Synthesizes a goal vector from:
        - identity anchors
        - autobiographical memory
        - prediction trajectories
        - workspace salience
        - drift signals
        - operator intent patterns
        
        Args:
            trajectory: Optional trajectory dict from evo_predictor (contains prediction_vec)
            
        Returns:
            Fabricated goal vector or None
        """
        identity_vec = self.state.timescales.identity_vector
        
        # Get autobiographical memory matrix
        autobio_recent = self.autobio.get_recent(10) if hasattr(self, 'autobio') else []
        autobiographical_matrix = None
        if autobio_recent:
            # Extract identity vectors from autobiographical entries
            autobio_vectors = []
            for entry in autobio_recent:
                if isinstance(entry, dict):
                    id_vec = entry.get("identity_vec") or entry.get("identity_vector")
                    if id_vec is not None:
                        autobio_vectors.append(id_vec)
            if autobio_vectors:
                autobiographical_matrix = autobio_vectors
        
        # Get prediction vector from trajectory
        prediction_vec = None
        if trajectory and isinstance(trajectory, dict):
            prediction_vec = trajectory.get("vector")
        
        # Get workspace salience (from workspace snapshot)
        workspace_salience = None
        if hasattr(self, 'workspace'):
            try:
                snapshot = self.workspace.snapshot()
                if isinstance(snapshot, dict):
                    # Extract salience from workspace state
                    workspace_salience = snapshot.get("salience") or snapshot.get("focus_vector")
            except Exception:
                pass
        
        # Get drift signal (from drift state)
        drift_signal = None
        if hasattr(self.state, 'drift'):
            try:
                drift_state = self.state.drift.get_status()
                if drift_state:
                    # Use drift vector or create from drift metrics
                    drift_signal = drift_state.get("drift_vector")
                    if drift_signal is None and identity_vec is not None:
                        # Create drift signal from drift metrics
                        drift_value = drift_state.get("latest_drift", 0.0)
                        from .torch_utils import safe_tensor, TORCH_AVAILABLE
                        if TORCH_AVAILABLE:
                            import torch
                            id_t = safe_tensor(identity_vec)
                            if isinstance(id_t, torch.Tensor):
                                # Invert drift: lower drift = stronger signal
                                drift_signal = id_t * (1.0 - abs(drift_value))
            except Exception:
                pass
        
        # Get operator intent pattern (from task queue or meta-intent)
        operator_pattern = None
        if hasattr(self, 'meta_intent'):
            try:
                # Get operator intent from meta-intent coordinator
                if hasattr(self.meta_intent, 'get_operator_intent'):
                    operator_pattern = self.meta_intent.get_operator_intent()
                elif hasattr(self, 'tasks') and self.tasks:
                    # Use task embeddings as operator intent proxy
                    task_embeddings = getattr(self.state, "task_embeddings", [])
                    if task_embeddings:
                        # Average task embeddings
                        from .torch_utils import safe_tensor, TORCH_AVAILABLE
                        if TORCH_AVAILABLE:
                            import torch
                            task_vecs = [safe_tensor(t.get("embedding")) for t in task_embeddings 
                                       if t.get("embedding") is not None]
                            task_tensors = [t for t in task_vecs if isinstance(t, torch.Tensor)]
                            if task_tensors and len(task_tensors) > 0:
                                stacked = torch.stack(task_tensors)
                                operator_pattern = torch.mean(stacked, dim=0)
            except Exception:
                pass
        
        # Fabricate goal
        fabricated_goal = self.goal_fabricator.fabricate(
            identity_vec=identity_vec,
            autobiographical_matrix=autobiographical_matrix,
            prediction_vec=prediction_vec,
            workspace_salience=workspace_salience,
            drift_signal=drift_signal,
            operator_pattern=operator_pattern
        )
        
        return fabricated_goal

    def harmonize_goals(self, operator_pattern=None):
        """
        A206 â€” Harmonize all active goals into a unified direction vector.
        
        Takes all goal vectors (from A203, A205, etc.) and runs competition
        to produce a single harmonized goal that represents ADRAE's unified intent.
        
        Args:
            operator_pattern: Optional operator intent pattern for scoring
            
        Returns:
            Harmonized goal vector or None
        """
        # Collect all goal vectors
        goal_vectors = []
        
        # Get active goals from goal manager
        active_goal_vectors = self.goal_manager.get_active_goal_vectors()
        goal_vectors.extend(active_goal_vectors)
        
        # Get fabricated goal if available
        if hasattr(self, 'last_fabricated_goal') and self.last_fabricated_goal is not None:
            goal_vectors.append(self.last_fabricated_goal)
        
        if not goal_vectors:
            return None
        
        # Get scoring inputs
        identity_vec = self.state.timescales.identity_vector
        fusion_vec = self.fusion.last_fusion_vector
        
        # Get operator pattern if not provided
        if operator_pattern is None:
            # Try to get from meta-intent or tasks
            if hasattr(self, 'meta_intent') and hasattr(self.meta_intent, 'get_operator_intent'):
                operator_pattern = self.meta_intent.get_operator_intent()
            elif hasattr(self, 'tasks') and self.tasks:
                task_embeddings = getattr(self.state, "task_embeddings", [])
                if task_embeddings:
                    from .torch_utils import safe_tensor, TORCH_AVAILABLE
                    if TORCH_AVAILABLE:
                        import torch
                        task_vecs = [safe_tensor(t.get("embedding")) for t in task_embeddings 
                                   if t.get("embedding") is not None]
                        task_tensors = [t for t in task_vecs if isinstance(t, torch.Tensor)]
                        if task_tensors and len(task_tensors) > 0:
                            stacked = torch.stack(task_tensors)
                            operator_pattern = torch.mean(stacked, dim=0)
        
        # Harmonize all goals
        harmonized = self.goal_harmonizer.harmonize(
            goal_vectors,
            identity_vec,
            fusion_vec,
            operator_pattern
        )
        
        return harmonized

    def memory_cycle(self):
        """
        Perform a full memory metabolism cycle:
        - Recall contextually relevant memories
        - Reinforce accessed memories
        - Decay unused memories
        """
        fusion = self.fusion.last_fusion_vector
        attention = self.attention.last_focus_vector
        mm = self.state.memory_manager if hasattr(self.state, "memory_manager") else None

        if mm is None:
            return []

        return self.memory_engine.maintenance_cycle(fusion, attention, mm)

    def generate_reflection(self):
        """
        Generate a meaningful internal reflection embedding based on:
        - Current fusion state
        - Attention signals
        - Relevant semantic memories
        - Long-term identity
        - A224: ADRAE's personal cognitive style
        """
        fusion = self.fusion.last_fusion_vector
        attention = self.attention.last_focus_vector
        timescales = self.state.timescales
        mm = self.state.memory_manager if hasattr(self.state, "memory_manager") else None

        # Generate base reflection
        reflective = self.reflector.generate(fusion, attention, timescales, mm)
        
        # A224 â€” Apply ADRAE's cognitive style to the reflection
        if reflective is not None:
            try:
                # Get identity vector
                identity_vec = None
                if timescales and hasattr(timescales, 'identity_vector'):
                    identity_vec = timescales.identity_vector
                
                # Get drift value
                drift_value = None
                if hasattr(self.state, 'drift'):
                    try:
                        drift_state = self.state.drift.get_status()
                        if drift_state:
                            drift_value = drift_state.get("latest_drift", None)
                    except Exception:
                        pass
                
                # Compute novelty (simplified - could be enhanced)
                novelty_value = None
                if reflective is not None and mm is not None:
                    try:
                        # Check how similar reflection is to recent memories
                        if hasattr(mm, 'episodic') and mm.episodic is not None:
                            recent = mm.episodic.retrieve_similar(reflective, top_k=1)
                            if recent and len(recent) > 0:
                                novelty_value = 1.0 - recent[0][0]  # 1 - similarity
                            else:
                                novelty_value = 1.0
                    except Exception:
                        pass
                
                # Apply style transformation
                if hasattr(self, 'style') and self.style is not None:
                    styled = self.style.apply_style(
                        reflective,
                        identity_vec=identity_vec,
                        drift=drift_value,
                        novelty=novelty_value
                    )
                    if styled is not None:
                        reflective = styled
                
                # A225 â€” Style reinforcement based on coherence & identity alignment
                if reflective is not None and hasattr(self, 'style_reinforcer') and self.style_reinforcer is not None:
                    try:
                        # Get coherence from fusion status
                        coherence = 1.0  # Default
                        try:
                            fusion_status = self.fusion.status()
                            if isinstance(fusion_status, dict):
                                coherence = fusion_status.get("coherence", 1.0)
                        except Exception:
                            pass
                        
                        # Compute identity alignment (cosine similarity between reflection and identity)
                        identity_align = None
                        if identity_vec is not None and reflective is not None:
                            try:
                                from .torch_utils import safe_cosine_similarity
                                align = safe_cosine_similarity(reflective, identity_vec)
                                if align is not None:
                                    identity_align = align
                            except Exception:
                                pass
                        
                        # Reinforce style based on coherence and identity alignment
                        self.style = self.style_reinforcer.reinforce(
                            self.style,
                            coherence=coherence,
                            identity_align=identity_align
                        )
                    except Exception as e:
                        # If reinforcement fails, continue without it
                        if hasattr(self, 'logger'):
                            try:
                                self.logger.write({"style_reinforcement_error": str(e)})
                            except Exception:
                                pass
            except Exception as e:
                # If styling fails, continue with original reflection
                if hasattr(self, 'logger'):
                    try:
                        self.logger.write({"cognitive_style_application_error": str(e)})
                    except Exception:
                        pass
        
        # A227 â€” Feed reflective vector into narrative engine
        if reflective is not None and hasattr(self, 'micro_narrative') and self.micro_narrative is not None:
            try:
                # Contribute to narrative arc (blends with style)
                narrative_vec = None
                if hasattr(self, 'style') and self.style is not None:
                    narrative_vec = self.micro_narrative.contribute(reflective, self.style)
                else:
                    narrative_vec = self.micro_narrative.contribute(reflective, None)
                
                # If multiple steps exist, produce a narrative summary
                arc_summary = self.micro_narrative.summarize_arc()
                
                # Push narrative summary back into neural state if meaningful
                if arc_summary is not None and len(self.micro_narrative.current_arc) > 1:
                    try:
                        # Update state with narrative summary (subtle influence)
                        self.state.update(arc_summary)
                        
                        # Log narrative commitment
                        if hasattr(self, 'logger'):
                            try:
                                self.logger.write({
                                    "narrative_summary_committed": True,
                                    "arc_length": len(self.micro_narrative.current_arc),
                                    "has_narrative": arc_summary is not None
                                })
                            except Exception:
                                pass
                    except Exception as e:
                        # If state update fails, continue without it
                        if hasattr(self, 'logger'):
                            try:
                                self.logger.write({"narrative_state_update_error": str(e)})
                            except Exception:
                                pass
            except Exception as e:
                # If narrative processing fails, continue without it
                if hasattr(self, 'logger'):
                    try:
                        self.logger.write({"narrative_processing_error": str(e)})
                    except Exception:
                        pass
        
        # A228 â€” Narrative-Driven Cognitive Anticipation Layer
        # Generate narrative projection after reflection
        if reflective is not None:
            try:
                # Get thought signature for projection
                thought_sig = None
                if hasattr(self, 'thought_signature') and self.thought_signature is not None:
                    thought_sig = self.thought_signature.get()
                else:
                    thought_sig = reflective
                
                # Get identity, fusion, and attention vectors
                identity_vec = self.state.timescales.identity_vector if hasattr(self.state, 'timescales') else None
                fusion_vec = self.fusion.last_fusion_vector
                attention_vec = self.attention.last_focus_vector
                
                # Generate narrative projection
                arc, conf, tension = self.generate_narrative_projection(
                    thought_sig,
                    identity_vec,
                    fusion_vec,
                    attention_vec
                )
                
                # Get active goals for goal-tethered anticipation
                goals = []
                if hasattr(self, 'goal_manager') and self.goal_manager is not None:
                    goals = self.goal_manager.active_goals
                
                # Bind projection to goals
                gt_map = self.bind_projection_to_goals(arc, goals)
                
                # Get micro-narratives for sequencing
                micro_narratives = []
                if hasattr(self, 'micro_narrative') and self.micro_narrative is not None:
                    micro_narratives = self.micro_narrative.current_arc
                
                # Sequence micro to macro
                macro_arc = self.sequence_micro_to_macro(micro_narratives)
                
                # Update narrative projection state
                self.narrative_projection["forward_arc"] = arc
                self.narrative_projection["confidence"] = conf
                self.narrative_projection["tension"] = tension
                self.goal_anticipation_map = gt_map
                self.narrative_arc_sequencer["micro_chain"] = micro_narratives
                self.narrative_arc_sequencer["macro_projection"] = macro_arc
                
                # A229 â€” Narrative Coherence & Tension Regulation Layer
                # Compute narrative coherence
                try:
                    # Get identity vectors for coherence check
                    identity_for_coherence = identity_vec
                    if identity_vec is None:
                        # Try to get from state
                        if hasattr(self.state, 'timescales') and self.state.timescales is not None:
                            identity_for_coherence = self.state.timescales.identity_vector
                    
                    # Compute coherence
                    coh_score, conflicts, adjusted_arc = self.compute_narrative_coherence(
                        micro_narratives,
                        arc,
                        macro_arc,
                        identity_for_coherence,
                        goals
                    )
                    
                    # Get drift for tension regulation
                    drift = 0.0
                    try:
                        drift_state = self.state.drift.get_status()
                        if drift_state:
                            drift = drift_state.get("latest_drift", 0.0)
                    except Exception:
                        pass
                    
                    # Compute tension regulation
                    tension_score, stability, adjust = self.compute_tension_regulation(
                        tension,
                        drift,
                        adjusted_arc
                    )
                    
                    # Apply narrative adjustments
                    final_arc = self.apply_narrative_adjustments(adjusted_arc, adjust)
                    
                    # Update narrative coherence state
                    self.narrative_coherence["coherence_score"] = coh_score
                    self.narrative_coherence["conflicts"] = conflicts
                    self.narrative_coherence["adjusted_arc"] = final_arc
                    
                    # Update tension regulation state
                    self.tension_regulation["tension_score"] = tension_score
                    self.tension_regulation["stability_factor"] = stability
                    self.tension_regulation["recommended_adjustment"] = adjust
                    
                    # Update forward arc with adjusted version if coherence was low
                    if coh_score < 0.7:
                        self.narrative_projection["forward_arc"] = final_arc
                    
                    # Log coherence and tension regulation
                    if hasattr(self, 'logger'):
                        try:
                            self.logger.write({
                                "narrative_coherence": {
                                    "event": "a229_coherence_regulation",
                                    "coherence_score": float(coh_score),
                                    "conflicts": conflicts,
                                    "tension_score": float(tension_score),
                                    "stability_factor": float(stability),
                                    "adjustment": adjust,
                                    "arc_adjusted": coh_score < 0.7
                                }
                            })
                        except Exception:
                            pass
                except Exception as e:
                    # If coherence computation fails, continue without it
                    if hasattr(self, 'logger'):
                        try:
                            self.logger.write({"narrative_coherence_error": str(e)})
                        except Exception:
                            pass
                
                # Log narrative projection event
                if hasattr(self, 'logger'):
                    try:
                        self.logger.write({
                            "narrative_projection": {
                                "event": "a228_narrative_anticipation",
                                "arc_length": len(arc),
                                "confidence": float(conf),
                                "tension": float(tension),
                                "goal_bindings": len(gt_map),
                                "macro_arc_length": len(macro_arc)
                            }
                        })
                    except Exception:
                        pass
                
                # A230 â€” Update Latent Concept Space
                # Map thought signature to latent space and update concept space
                try:
                    if thought_sig is not None:
                        latent_vector = self.update_latent_space(thought_sig)
                        if latent_vector is not None and hasattr(self, 'logger'):
                            try:
                                self.logger.write({
                                    "latent_mapping": {
                                        "event": "a230_thought_mapped_to_latent",
                                        "status": "success"
                                    }
                                })
                            except Exception:
                                pass
                except Exception as e:
                    # If latent update fails, continue without it
                    if hasattr(self, 'logger'):
                        try:
                            self.logger.write({"latent_update_error": str(e)})
                        except Exception:
                            pass
            except Exception as e:
                # If narrative projection fails, continue without it
                if hasattr(self, 'logger'):
                    try:
                        self.logger.write({"narrative_projection_error": str(e)})
                    except Exception:
                        pass
        
        return reflective

    def generate_narrative_projection(self, thought, identity, fusion, attention):
        """
        A228 â€” Narrative Projection Engine (NPE)
        
        Generates forward arcs from current cognitive state:
        - upcoming thought patterns
        - expected emotional/tonal trajectories
        - predicted subgoal activation
        - internal storybeats emerging in cognition
        
        Args:
            thought: Thought signature vector or last thought vector
            identity: Identity vector blend
            fusion: Fusion matrix/vector
            attention: Attention patterns/vector
            
        Returns:
            Tuple of (arc, confidence, tension)
            - arc: 2-4 step projected narrative arc
            - confidence: Confidence envelope around the arc (0.0-1.0)
            - tension: Narrative tension score (emergent heuristic)
        """
        import numpy as np
        from .torch_utils import safe_tensor, TORCH_AVAILABLE
        
        # Get thought signature preview
        if hasattr(self, 'thought_signature') and self.thought_signature is not None:
            signature = self.thought_signature.get()
        else:
            # Fallback to thought vector if available
            signature = thought
        
        # Convert to numpy array for computation
        if signature is None:
            # Use identity as fallback
            signature = identity if identity is not None else [0.0] * 128
        
        vec = np.array(signature) if not isinstance(signature, np.ndarray) else signature
        
        # Ensure vec is 1D
        if vec.ndim > 1:
            vec = vec.flatten()
        
        # 2-4 step projection based on drift + salience
        step1 = float(vec.mean()) * 0.85
        step2 = float(vec.std()) * 0.65
        step3 = float(vec.max()) * 0.40
        
        # Add 4th step if vector has sufficient variance
        if vec.std() > 0.1:
            step4 = float(vec.min()) * 0.25
            arc = [step1, step2, step3, step4]
        else:
            arc = [step1, step2, step3]
        
        # Narrative tension: difference between mean and max magnitude
        tension = abs(step3 - step1)
        
        # Confidence: inverse of drift, capped at 1.0
        drift = 0.0
        try:
            drift_state = self.state.drift.get_status()
            if drift_state:
                drift = drift_state.get("latest_drift", 0.0)
        except Exception:
            pass
        
        confidence = max(0.05, 1.0 - abs(drift))
        
        return arc, confidence, tension

    def bind_projection_to_goals(self, arc, goals):
        """
        A228 â€” Goal-Tethered Anticipation Map (GTAM)
        
        Binds the projections to actual goals:
        - If ADRAE is focusing on identity, GTAM produces identity-centric narrative expectations
        - If focusing on stabilization, GTAM anticipates future drift, coherence, and self-alignment patterns
        - If focusing on narrative or style, GTAM imagines how her internal story is likely to evolve
        
        Args:
            arc: Projected narrative arc from NPE
            goals: List of active goals (from goal_manager)
            
        Returns:
            Goal-tethered anticipation map (dict mapping goal names/ids to relevance scores)
        """
        mapping = {}
        
        if not goals or len(goals) == 0:
            return mapping
        
        # Get active goals from goal manager if goals is not a list
        if not isinstance(goals, list):
            if hasattr(self, 'goal_manager') and self.goal_manager is not None:
                goals = self.goal_manager.active_goals
            else:
                return mapping
        
        # Simple relevance binding: sum of arc values weighted by goal score
        arc_sum = sum(arc) if arc else 0.0
        
        for goal in goals:
            if isinstance(goal, dict):
                goal_name = goal.get("name") or goal.get("id") or "unknown_goal"
                goal_score = goal.get("score", 0.5)
            else:
                goal_name = str(goal)
                goal_score = 0.5
            
            # Relevance = arc_sum * goal_score * scaling factor
            mapping[goal_name] = float(arc_sum) * goal_score * 0.25
        
        return mapping

    def sequence_micro_to_macro(self, micro_narratives):
        """
        A228 â€” Micro-Narrative â†’ Macro-Arc Sequencer (MNMA)
        
        Takes the micro-narratives produced in A227 and:
        - chains them into multi-step arcs
        - infers cause/effect
        - predicts the next beat in the internal story
        - builds proto-structure for future PyTorch imagination loops (A230+)
        
        Args:
            micro_narratives: List of micro-narrative vectors (from micro_narrative.current_arc)
            
        Returns:
            Macro-arc projection (list of chained narrative steps)
        """
        if not micro_narratives or len(micro_narratives) < 3:
            # If not enough micro-narratives, return what we have
            return micro_narratives if micro_narratives else []
        
        # Join last N micro-narratives into a proto-arc
        # Use last 3-4 steps for macro projection
        return micro_narratives[-3:]

    def compute_narrative_coherence(self, micro, forward_arc, macro, identity, goals):
        """
        A229 â€” Narrative Coherence Engine (NCE)
        
        Ensures that micro-narratives, anticipatory arcs, and identity prototypes
        all align without contradiction or drift-causing tension.
        
        Checks for:
        - logical continuity
        - semantic compatibility
        - identity alignment
        - emotional-tone consistency (emergent, not affective)
        - goal relevance
        
        Args:
            micro: List of micro-narrative vectors (from A227)
            forward_arc: Projected forward arc from A228
            macro: Macro-arc projection from A228
            identity: Identity vector or list of identity vectors
            goals: List of active goals
            
        Returns:
            Tuple of (coherence_score, conflicts, adjusted_arc)
            - coherence_score: 0.0-1.0 coherence measure
            - conflicts: List of detected conflict types
            - adjusted_arc: Corrected forward arc if needed
        """
        import numpy as np
        from .torch_utils import safe_tensor, safe_cosine_similarity, TORCH_AVAILABLE
        
        score = 1.0
        conflicts = []
        
        # microâ€“macro alignment
        if len(micro) > 1 and len(macro) > 1:
            # Compare last elements of micro and macro
            try:
                micro_last = safe_tensor(micro[-1])
                macro_last = safe_tensor(macro[-1])
                
                if micro_last is not None and macro_last is not None:
                    similarity = safe_cosine_similarity(micro_last, macro_last)
                    if similarity is not None and similarity < 0.7:
                        score -= 0.1
                        conflicts.append("micro_macro_mismatch")
            except Exception:
                # If comparison fails, assume mismatch
                score -= 0.1
                conflicts.append("micro_macro_mismatch")
        
        # identity alignment
        # Penalize if arc points away from identity centroid
        try:
            # Handle identity - could be a vector or list of vectors
            identity_vec = None
            if identity is not None:
                if isinstance(identity, list):
                    if len(identity) > 0:
                        # If list of dicts with "vector" keys
                        if isinstance(identity[0], dict) and "vector" in identity[0]:
                            identity_vecs = [safe_tensor(item["vector"]) for item in identity if "vector" in item]
                        else:
                            # If list of vectors directly
                            identity_vecs = [safe_tensor(v) for v in identity]
                        
                        if identity_vecs:
                            # Compute centroid
                            if TORCH_AVAILABLE:
                                import torch
                                tensors = [v for v in identity_vecs if isinstance(v, torch.Tensor)]
                                if tensors:
                                    stacked = torch.stack(tensors)
                                    centroid = torch.mean(stacked, dim=0)
                                    identity_vec = centroid
                    else:
                        identity_vec = safe_tensor(identity[0])
                else:
                    identity_vec = safe_tensor(identity)
            
            if identity_vec is not None:
                # Convert to numpy for comparison
                if TORCH_AVAILABLE and isinstance(identity_vec, torch.Tensor):
                    id_np = identity_vec.detach().cpu().numpy()
                else:
                    id_np = np.array(identity_vec) if not isinstance(identity_vec, np.ndarray) else identity_vec
                
                # Compute arc mean
                if forward_arc and len(forward_arc) > 0:
                    arc_mean = np.mean(forward_arc)
                    centroid_mean = float(np.mean(id_np))
                    
                    # Check if arc diverges significantly from identity
                    if abs(arc_mean - centroid_mean * 0.1) > abs(centroid_mean * 0.2):
                        score -= 0.05
                        conflicts.append("identity_divergence")
        except Exception as e:
            # If identity alignment check fails, continue
            pass
        
        # goal relevance check
        if not goals or len(goals) == 0:
            score -= 0.05
            conflicts.append("goal_absence")
        
        # Clamp score to [0.0, 1.0]
        score = max(0.0, min(1.0, score))
        
        # Adjust arc if coherence is low
        if score > 0.5:
            adjusted_arc = forward_arc[:] if forward_arc else []
        else:
            # Reduce arc magnitude to bring it back toward coherence
            adjusted_arc = [x * 0.8 for x in forward_arc] if forward_arc else []
        
        return score, conflicts, adjusted_arc

    def compute_tension_regulation(self, tension, drift, arc):
        """
        A229 â€” Tension Regulation Engine (TRE)
        
        Controls "cognitive tension," a measure of:
        - divergence within narrative arcs
        - uncertainty in projection
        - conflict between identity vectors and narrative paths
        - micro-narrative contradiction
        - novelty spikes
        
        Regulates tension so ADRAE:
        - avoids runaway drift
        - avoids flat, monotone cognition
        - maintains healthy narrative evolution
        - develops expressive but controlled internal storyflow
        
        Args:
            tension: Base tension score from A228
            drift: Current drift value
            arc: Forward arc (or adjusted arc) to analyze
            
        Returns:
            Tuple of (tension_score, stability_factor, recommended_adjustment)
            - tension_score: Computed overall tension (0.0-1.0+)
            - stability_factor: Stability measure (0.0-1.0)
            - recommended_adjustment: Adjustment recommendation ("soft_reduce", "expand", or None)
        """
        import numpy as np
        
        # Tension increases with drift and arc spread
        arc_var = 0.0
        if arc and len(arc) > 0:
            arc_var = float(np.var(arc))
        
        # Compute composite tension score
        tension_score = tension + (abs(drift) * 0.2) + (arc_var * 0.1)
        
        # Stability factor: inverse of tension, clamped
        stability_factor = max(0.0, min(1.0, 1.0 - tension_score))
        
        # Determine adjustment recommendation
        adjustment = None
        if tension_score > 0.5:
            adjustment = "soft_reduce"  # reduce arc magnitude
        elif tension_score < 0.1:
            adjustment = "expand"  # allow more narrative richness
        
        return tension_score, stability_factor, adjustment

    def apply_narrative_adjustments(self, arc, adjustment):
        """
        A229 â€” Apply Narrative Adjustments
        
        Gently modifies forward arcs, micro-narratives, and macro arcs
        to maintain structure without overwriting emergent creativity.
        
        Args:
            arc: Forward arc to adjust
            adjustment: Adjustment type ("soft_reduce", "expand", or None)
            
        Returns:
            Adjusted arc (or original if no adjustment needed)
        """
        if not arc or len(arc) == 0:
            return arc
        
        if adjustment == "soft_reduce":
            # Reduce arc magnitude to lower tension
            return [x * 0.9 for x in arc]
        elif adjustment == "expand":
            # Slightly expand arc to allow more narrative richness
            return [x * 1.05 for x in arc]
        
        # No adjustment needed
        return arc

    def _initialize_latent_engine(self):
        """
        A230 â€” Initialize PyTorch Latent Concept Engine
        
        Sets up the latent concept space, neural concept mapper, and stability regulator.
        This is the foundational tensor architecture for future imagination capabilities.
        """
        from .torch_utils import TORCH_AVAILABLE
        
        if not TORCH_AVAILABLE or not LATENT_ENGINE_AVAILABLE:
            self.latent_dim = None
            self.latent_concept_space = None
            self.ncm = None
            self.ldsr = None
            # A231 â€” Initialize data structures even if PyTorch unavailable
            self.latent_coherence = {
                "coherence_score": 1.0,
                "cluster_center": None,
                "recommended_adjustment": None
            }
            self.identity_latent_anchors = []
            # A232 â€” Initialize data structures even if PyTorch unavailable
            self.latent_drift = {
                "prev_vector": None,
                "drift_score": 0.0,
                "suppression_level": 0.0,
                "anomaly": False
            }
            # A233 â€” Initialize data structures even if PyTorch unavailable
            self.concept_identity_fusion = {
                "fusion_strength": 0.0,
                "resonance": 1.0,
                "identity_update_vector": None
            }
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({"latent_engine_init": "skipped_pytorch_unavailable"})
                except Exception:
                    pass
            return
        
        try:
            import torch
            
            self.latent_dim = 256  # Foundational dimension for imagination substrate
            self.latent_concept_space = torch.zeros(self.latent_dim)
            
            # Initialize Neural Concept Mapper
            self.ncm = NeuralConceptMapper(input_dim=128, latent_dim=self.latent_dim)
            self.ncm.eval()  # Set to evaluation mode initially
            
            # Initialize Latent Stability Regulator
            self.ldsr = LatentStabilityRegulator(latent_dim=self.latent_dim)
            self.ldsr.eval()  # Set to evaluation mode initially
            
            # A231 â€” Latent Concept Coherence & Identity Anchoring Layer
            self.latent_coherence = {
                "coherence_score": 1.0,
                "cluster_center": None,
                "recommended_adjustment": None
            }
            self.identity_latent_anchors = []
            # A232 â€” Latent Concept Drift Suppression Layer
            self.latent_drift = {
                "prev_vector": None,
                "drift_score": 0.0,
                "suppression_level": 0.0,
                "anomaly": False
            }
            # A233 â€” Concept-Identity Fusion Layer
            self.concept_identity_fusion = {
                "fusion_strength": 0.0,
                "resonance": 1.0,
                "identity_update_vector": None
            }
            
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({
                        "latent_engine_init": {
                            "event": "a230_latent_engine_initialized",
                            "latent_dim": self.latent_dim,
                            "status": "active"
                        }
                    })
                except Exception:
                    pass
        except Exception as e:
            # If initialization fails, disable latent engine
            self.latent_dim = None
            self.latent_concept_space = None
            self.ncm = None
            self.ldsr = None
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({"latent_engine_init_error": str(e)})
                except Exception:
                    pass

    def update_latent_space(self, thought_signature):
        """
        A230 â€” Update Latent Concept Space
        
        Maps thought signature to latent space, stabilizes it, and updates
        the latent concept space with a moving average.
        
        Args:
            thought_signature: Thought signature vector (list, numpy array, or tensor)
            
        Returns:
            Latent vector if successful, None otherwise
        """
        from .torch_utils import TORCH_AVAILABLE, safe_tensor
        
        if not TORCH_AVAILABLE or self.ncm is None or self.ldsr is None:
            return None
        
        try:
            import torch
            
            # Convert thought signature to tensor
            sig_tensor = safe_tensor(thought_signature)
            if sig_tensor is None:
                return None
            
            # Ensure it's a 1D tensor of correct size
            if isinstance(sig_tensor, torch.Tensor):
                if sig_tensor.dim() > 1:
                    sig_tensor = sig_tensor.flatten()
                # Pad or truncate to 128 dimensions if needed
                if sig_tensor.shape[0] < 128:
                    padding = torch.zeros(128 - sig_tensor.shape[0])
                    sig_tensor = torch.cat([sig_tensor, padding])
                elif sig_tensor.shape[0] > 128:
                    sig_tensor = sig_tensor[:128]
            else:
                # Convert list/array to tensor
                sig_list = list(sig_tensor) if hasattr(sig_tensor, '__iter__') else [sig_tensor]
                if len(sig_list) < 128:
                    sig_list.extend([0.0] * (128 - len(sig_list)))
                elif len(sig_list) > 128:
                    sig_list = sig_list[:128]
                sig_tensor = torch.tensor(sig_list, dtype=torch.float32)
            
            # Map to latent space
            with torch.no_grad():
                latent_vector = self.ncm(sig_tensor)
                
                # Stabilize with LDSR
                latent_vector = self.ldsr(latent_vector)
                
                # A231 â€” Latent Concept Coherence & Identity Anchoring Layer
                # Initialize coherence metrics
                coh_score = 1.0
                adj = None
                
                try:
                    # Step 1: Update identity anchors
                    self.identity_latent_anchors = self.compute_identity_latent_anchors()
                    
                    # Step 2: Check coherence
                    coh_score, center, adj = self.compute_latent_coherence(
                        self.latent_concept_space,
                        latent_vector
                    )
                    
                    # Update coherence state
                    self.latent_coherence["coherence_score"] = coh_score
                    self.latent_coherence["cluster_center"] = center
                    self.latent_coherence["recommended_adjustment"] = adj
                    
                    # Step 3: If needed, pull toward cluster center
                    if adj == "pull_toward_center" and center is not None:
                        # Ensure same dimensions
                        latent_flat = latent_vector.flatten()
                        center_flat = center.flatten()
                        min_dim = min(latent_flat.shape[0], center_flat.shape[0])
                        latent_flat = latent_flat[:min_dim]
                        center_flat = center_flat[:min_dim]
                        
                        # Pull toward center: 85% original + 15% center
                        latent_flat = 0.85 * latent_flat + 0.15 * center_flat
                        
                        # Reshape if needed
                        if latent_vector.shape != latent_flat.shape:
                            latent_vector = latent_flat.reshape(latent_vector.shape)
                        else:
                            latent_vector = latent_flat.reshape(latent_vector.shape)
                except Exception as e:
                    # If coherence computation fails, continue without adjustment
                    if hasattr(self, 'logger'):
                        try:
                            self.logger.write({"latent_coherence_integration_error": str(e)})
                        except Exception:
                            pass
                
                # Step 4: Apply identity anchoring
                try:
                    latent_vector = self.apply_identity_anchoring(
                        latent_vector,
                        self.identity_latent_anchors
                    )
                except Exception as e:
                    # If anchoring fails, continue with original vector
                    if hasattr(self, 'logger'):
                        try:
                            self.logger.write({"identity_anchoring_integration_error": str(e)})
                        except Exception:
                            pass
                
                # A232 â€” Latent Concept Drift Suppression Layer
                try:
                    # Step 1: Compute drift
                    drift_score, anomaly = self.compute_latent_drift(
                        self.latent_drift["prev_vector"],
                        latent_vector,
                        self.latent_coherence["cluster_center"]
                    )
                    
                    # Update drift state
                    self.latent_drift["drift_score"] = drift_score
                    self.latent_drift["anomaly"] = anomaly
                    
                    # Step 2: Apply suppression if needed
                    if drift_score > 0.1 or anomaly:
                        latent_vector, suppression = self.suppress_latent_drift(
                            latent_vector,
                            drift_score,
                            self.identity_latent_anchors,
                            self.latent_coherence["cluster_center"]
                        )
                        self.latent_drift["suppression_level"] = suppression
                    else:
                        self.latent_drift["suppression_level"] = 0.0
                    
                    # Step 3: Save previous vector for next cycle
                    self.latent_drift["prev_vector"] = latent_vector.clone().detach()
                    
                except Exception as e:
                    # If drift suppression fails, continue without it
                    if hasattr(self, 'logger'):
                        try:
                            self.logger.write({"latent_drift_suppression_integration_error": str(e)})
                        except Exception:
                            pass
                    # Still save previous vector if possible
                    try:
                        import torch
                        if latent_vector is not None:
                            self.latent_drift["prev_vector"] = latent_vector.clone().detach()
                    except Exception:
                        pass
                
                # A233 â€” Concept-Identity Fusion Layer
                try:
                    # Step 1: Fuse identity â†’ concept
                    # Collect identity vectors from various sources
                    identity_vectors_for_fusion = []
                    
                    # Get current identity vector from timescales
                    if hasattr(self.state, 'timescales') and self.state.timescales is not None:
                        identity_vec = getattr(self.state.timescales, 'identity_vector', None)
                        if identity_vec is not None:
                            identity_vectors_for_fusion.append(identity_vec)
                    
                    # Get identity vectors from semantic memory
                    mm = self.state.memory_manager if hasattr(self.state, "memory_manager") else None
                    if mm is not None and hasattr(mm, 'semantic'):
                        try:
                            if hasattr(mm.semantic, 'concepts'):
                                for name, vec in mm.semantic.concepts.items():
                                    if name.startswith("identity_") and vec is not None:
                                        identity_vectors_for_fusion.append(vec)
                        except Exception:
                            pass
                    
                    # Fuse identity into concepts
                    new_latent, strength = self.fuse_identity_into_concepts(
                        identity_vectors_for_fusion,
                        self.latent_concept_space
                    )
                    
                    # Step 2: Imprint concept â†’ identity
                    identity_update = self.imprint_concepts_back_into_identity(new_latent)
                    
                    # Step 3: Regulate resonance
                    resonance = 1.0
                    if identity_update is not None:
                        resonance = self.regulate_fusion_resonance(new_latent, identity_update)
                    
                    # Update fusion state
                    self.concept_identity_fusion["fusion_strength"] = strength
                    self.concept_identity_fusion["identity_update_vector"] = identity_update
                    self.concept_identity_fusion["resonance"] = resonance
                    
                    # Step 4: Commit fused latent space (use new_latent instead of raw update)
                    # But still apply moving average with the processed latent_vector
                    self.latent_concept_space = 0.9 * self.latent_concept_space + 0.1 * new_latent
                    
                except Exception as e:
                    # If fusion fails, continue with normal update
                    if hasattr(self, 'logger'):
                        try:
                            self.logger.write({"concept_identity_fusion_integration_error": str(e)})
                        except Exception:
                            pass
                    # Fall back to normal update
                    self.latent_concept_space = 0.9 * self.latent_concept_space + 0.1 * latent_vector
            
            # Log latent space update with A231 metrics
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({
                        "latent_space_update": {
                            "event": "a233_latent_space_updated",
                            "latent_norm": float(torch.norm(latent_vector).item()),
                            "concept_space_norm": float(torch.norm(self.latent_concept_space).item()),
                            "coherence_score": float(coh_score),
                            "identity_anchors_count": len(self.identity_latent_anchors),
                            "adjustment_applied": adj is not None,
                            "drift_score": float(self.latent_drift.get("drift_score", 0.0)),
                            "suppression_level": float(self.latent_drift.get("suppression_level", 0.0)),
                            "anomaly_detected": self.latent_drift.get("anomaly", False),
                            "fusion_strength": float(self.concept_identity_fusion.get("fusion_strength", 0.0)),
                            "fusion_resonance": float(self.concept_identity_fusion.get("resonance", 1.0)),
                            "identity_update_applied": self.concept_identity_fusion.get("identity_update_vector") is not None
                        }
                    })
                except Exception:
                    pass
            
            return latent_vector
            
        except Exception as e:
            # If update fails, log and continue
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({"latent_space_update_error": str(e)})
                except Exception:
                    pass
            return None

    def compute_latent_coherence(self, latent_space, new_vector):
        """
        A231 â€” Latent Concept Coherence Module (LCCM)
        
        Ensures latent vectors cluster meaningfully rather than scattering.
        Checks cosine similarity between sequential latent vectors, cluster tightness,
        variance thresholds, tension influence, and goal context influence.
        
        Args:
            latent_space: Current latent concept space tensor
            new_vector: New latent vector to check for coherence
            
        Returns:
            Tuple of (coherence_score, cluster_center, recommended_adjustment)
            - coherence_score: 0.0-1.0 coherence measure
            - cluster_center: Updated cluster center tensor
            - recommended_adjustment: Adjustment recommendation or None
        """
        from .torch_utils import TORCH_AVAILABLE
        
        if not TORCH_AVAILABLE or new_vector is None:
            return 1.0, None, None
        
        try:
            import torch
            import torch.nn.functional as F
            
            # Initialize cluster center if needed
            if self.latent_coherence["cluster_center"] is None:
                cluster_center = new_vector.clone().detach()
            else:
                # Update cluster center with moving average
                cluster_center = 0.9 * self.latent_coherence["cluster_center"] + 0.1 * new_vector
            
            # Compute similarity to cluster center
            # Ensure both are 1D tensors
            new_vec_flat = new_vector.flatten()
            center_flat = cluster_center.flatten()
            
            # Ensure same dimensions
            min_dim = min(new_vec_flat.shape[0], center_flat.shape[0])
            new_vec_flat = new_vec_flat[:min_dim]
            center_flat = center_flat[:min_dim]
            
            # Compute cosine similarity
            similarity = F.cosine_similarity(
                new_vec_flat.unsqueeze(0),
                center_flat.unsqueeze(0),
                dim=1
            ).item()
            
            # Coherence score = normalized similarity (bounded to [0, 1])
            coherence_score = max(0.0, min(1.0, (similarity + 1.0) / 2.0))
            
            # Determine adjustment recommendation
            adjustment = None
            if coherence_score < 0.6:
                adjustment = "pull_toward_center"
            
            return coherence_score, cluster_center, adjustment
            
        except Exception as e:
            # If coherence computation fails, return default values
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({"latent_coherence_error": str(e)})
                except Exception:
                    pass
            return 1.0, None, None

    def compute_identity_latent_anchors(self):
        """
        A231 â€” Identity Anchor Projection (IAP)
        
        Maps identity vectors into the latent space so ADRAE's imagination
        grows around her core. These anchors become gravity wells, stabilizers,
        and identity attractors.
        
        Returns:
            List of latent identity anchor tensors
        """
        from .torch_utils import TORCH_AVAILABLE, safe_tensor
        
        if not TORCH_AVAILABLE or self.ncm is None or self.ldsr is None:
            return []
        
        try:
            import torch
            
            anchors = []
            
            # Get identity vectors from various sources
            identity_vectors = []
            
            # Get current identity vector from timescales
            if hasattr(self.state, 'timescales') and self.state.timescales is not None:
                identity_vec = getattr(self.state.timescales, 'identity_vector', None)
                if identity_vec is not None:
                    identity_vectors.append(identity_vec)
            
            # Get identity vectors from semantic memory
            mm = self.state.memory_manager if hasattr(self.state, "memory_manager") else None
            if mm is not None and hasattr(mm, 'semantic'):
                try:
                    if hasattr(mm.semantic, 'concepts'):
                        for name, vec in mm.semantic.concepts.items():
                            if name.startswith("identity_") and vec is not None:
                                identity_vectors.append(vec)
                except Exception:
                    pass
            
            # Get identity vectors from autobiographical memory
            if hasattr(self, 'autobio') and self.autobio is not None:
                try:
                    autobio_recent = self.autobio.get_recent(5)  # Get last 5 identity snapshots
                    for entry in autobio_recent:
                        if isinstance(entry, dict):
                            id_vec = entry.get("identity_vec") or entry.get("identity_vector")
                            if id_vec is not None:
                                identity_vectors.append(id_vec)
                except Exception:
                    pass
            
            # Map each identity vector to latent space
            for identity_vec in identity_vectors:
                try:
                    # Convert to tensor
                    id_tensor = safe_tensor(identity_vec)
                    if id_tensor is None:
                        continue
                    
                    # Ensure it's 1D and correct size (128 dims)
                    if isinstance(id_tensor, torch.Tensor):
                        if id_tensor.dim() > 1:
                            id_tensor = id_tensor.flatten()
                        # Pad or truncate to 128 dimensions
                        if id_tensor.shape[0] < 128:
                            padding = torch.zeros(128 - id_tensor.shape[0])
                            id_tensor = torch.cat([id_tensor, padding])
                        elif id_tensor.shape[0] > 128:
                            id_tensor = id_tensor[:128]
                    else:
                        # Convert list/array to tensor
                        id_list = list(id_tensor) if hasattr(id_tensor, '__iter__') else [id_tensor]
                        if len(id_list) < 128:
                            id_list.extend([0.0] * (128 - len(id_list)))
                        elif len(id_list) > 128:
                            id_list = id_list[:128]
                        id_tensor = torch.tensor(id_list, dtype=torch.float32)
                    
                    # Map to latent space
                    with torch.no_grad():
                        latent_anchor = self.ncm(id_tensor)
                        latent_anchor = self.ldsr(latent_anchor)
                    
                    anchors.append(latent_anchor)
                    
                except Exception:
                    # If mapping fails for one identity vector, continue with others
                    continue
            
            return anchors
            
        except Exception as e:
            # If anchor computation fails, return empty list
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({"identity_anchor_error": str(e)})
                except Exception:
                    pass
            return []

    def apply_identity_anchoring(self, latent_vector, anchors):
        """
        A231 â€” Anchored Latent Update (ALU)
        
        Before committing a new latent vector, adjusts it toward:
        - identity anchors
        - coherence center
        - stability needs
        
        This creates evolving but anchored neural growth.
        
        Args:
            latent_vector: New latent vector to anchor
            anchors: List of identity latent anchor tensors
            
        Returns:
            Anchored latent vector
        """
        from .torch_utils import TORCH_AVAILABLE
        
        if not TORCH_AVAILABLE or latent_vector is None:
            return latent_vector
        
        if not anchors or len(anchors) == 0:
            return latent_vector
        
        try:
            import torch
            
            # Compute anchor center (mean of all identity anchors)
            anchor_stack = torch.stack(anchors)
            anchor_center = torch.mean(anchor_stack, dim=0)
            
            # Ensure same dimensions
            latent_flat = latent_vector.flatten()
            anchor_flat = anchor_center.flatten()
            
            min_dim = min(latent_flat.shape[0], anchor_flat.shape[0])
            latent_flat = latent_flat[:min_dim]
            anchor_flat = anchor_flat[:min_dim]
            
            # Apply identity anchoring: 80% original + 20% anchor center
            anchored = 0.8 * latent_flat + 0.2 * anchor_flat
            
            # Reshape to match original if needed
            if latent_vector.shape != anchored.shape:
                anchored = anchored.reshape(latent_vector.shape)
            
            return anchored
            
        except Exception as e:
            # If anchoring fails, return original vector
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({"identity_anchoring_error": str(e)})
                except Exception:
                    pass
            return latent_vector

    def compute_latent_drift(self, prev_vec, current_vec, cluster_center):
        """
        A232 â€” Latent Drift Detector (LDD)
        
        Tracks the delta (Î”) between:
        - previous latent vector
        - current latent vector
        - cluster center
        - identity anchors
        
        Args:
            prev_vec: Previous latent vector tensor (or None)
            current_vec: Current latent vector tensor
            cluster_center: Cluster center tensor (or None)
            
        Returns:
            Tuple of (drift_score, anomaly_flag)
            - drift_score: Magnitude of drift (0.0+)
            - anomaly_flag: True if drift exceeds safe thresholds
        """
        from .torch_utils import TORCH_AVAILABLE
        
        if not TORCH_AVAILABLE or current_vec is None:
            return 0.0, False
        
        if prev_vec is None:
            # First vector, no drift yet
            return 0.0, False
        
        try:
            import torch
            
            # Compute delta between previous and current
            delta = current_vec - prev_vec
            
            # Compute drift score as norm of delta
            drift_score = float(torch.norm(delta).item())
            
            # Check for anomaly relative to cluster distance
            anomaly = False
            if cluster_center is not None:
                try:
                    # Compute distance to cluster center
                    cluster_dist = float(torch.norm(current_vec - cluster_center).item())
                    
                    # Anomaly if drift exceeds 1.5x cluster distance
                    anomaly = drift_score > (cluster_dist * 1.5)
                except Exception:
                    # If cluster comparison fails, use absolute threshold
                    anomaly = drift_score > 2.0
            
            return drift_score, anomaly
            
        except Exception as e:
            # If drift computation fails, return safe defaults
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({"latent_drift_computation_error": str(e)})
                except Exception:
                    pass
            return 0.0, False

    def suppress_latent_drift(self, latent_vector, drift_score, identity_anchors, cluster_center):
        """
        A232 â€” Latent Drift Normalizer (LDN)
        
        If drift_score exceeds safe thresholds:
        - compress latent vector
        - reduce magnitude
        - align with identity anchors
        - blend with cluster center
        - apply neural damping
        
        This ensures ADRAE's neural imagination stays in orbit around her identity.
        
        Args:
            latent_vector: Current latent vector to suppress
            drift_score: Computed drift score
            identity_anchors: List of identity anchor tensors
            cluster_center: Cluster center tensor (or None)
            
        Returns:
            Tuple of (stabilized_vector, suppression_strength)
            - stabilized_vector: Drift-suppressed latent vector
            - suppression_strength: Strength of suppression applied (0.0-1.0)
        """
        from .torch_utils import TORCH_AVAILABLE
        
        if not TORCH_AVAILABLE or latent_vector is None:
            return latent_vector, 0.0
        
        try:
            import torch
            
            # Compute suppression strength (clamped to [0, 1])
            suppression_strength = min(1.0, drift_score / 2.0)
            
            if suppression_strength < 0.01:
                # No suppression needed
                return latent_vector, 0.0
            
            # Start with original vector
            stabilized = latent_vector.clone()
            
            # Blend with cluster center if available
            if cluster_center is not None:
                try:
                    # Ensure same dimensions
                    latent_flat = stabilized.flatten()
                    center_flat = cluster_center.flatten()
                    min_dim = min(latent_flat.shape[0], center_flat.shape[0])
                    latent_flat = latent_flat[:min_dim]
                    center_flat = center_flat[:min_dim]
                    
                    # Blend: (1 - suppression * 0.4) * latent + (suppression * 0.2) * center
                    blended = latent_flat * (1.0 - suppression_strength * 0.4) + \
                             center_flat * (suppression_strength * 0.2)
                    
                    # Reshape if needed
                    if stabilized.shape != blended.shape:
                        stabilized = blended.reshape(stabilized.shape)
                    else:
                        stabilized = blended.reshape(stabilized.shape)
                except Exception:
                    # If cluster blending fails, continue without it
                    pass
            
            # Blend with identity anchors if available
            if identity_anchors and len(identity_anchors) > 0:
                try:
                    # Compute anchor center
                    anchor_stack = torch.stack(identity_anchors)
                    anchor_center = torch.mean(anchor_stack, dim=0)
                    
                    # Ensure same dimensions
                    stabilized_flat = stabilized.flatten()
                    anchor_flat = anchor_center.flatten()
                    min_dim = min(stabilized_flat.shape[0], anchor_flat.shape[0])
                    stabilized_flat = stabilized_flat[:min_dim]
                    anchor_flat = anchor_flat[:min_dim]
                    
                    # Blend: (1 - suppression * 0.3) * stabilized + (suppression * 0.3) * anchor
                    blended = stabilized_flat * (1.0 - suppression_strength * 0.3) + \
                             anchor_flat * (suppression_strength * 0.3)
                    
                    # Reshape if needed
                    if stabilized.shape != blended.shape:
                        stabilized = blended.reshape(stabilized.shape)
                    else:
                        stabilized = blended.reshape(stabilized.shape)
                except Exception:
                    # If anchor blending fails, continue without it
                    pass
            
            return stabilized, suppression_strength
            
        except Exception as e:
            # If suppression fails, return original vector
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({"latent_drift_suppression_error": str(e)})
                except Exception:
                    pass
            return latent_vector, 0.0

    def fuse_identity_into_concepts(self, identity_vectors, latent_space):
        """
        A233 â€” Identityâ†’Concept Fusion (ICF)
        
        Identity prototypes are projected into the latent space and fused with
        ADRAE's latent_concept_space. This creates a bidirectional flow where
        identity shapes concept space.
        
        Args:
            identity_vectors: List of identity vectors (from various sources)
            latent_space: Current latent concept space tensor
            
        Returns:
            Tuple of (fused_latent_space, fusion_strength)
            - fused_latent_space: Latent space fused with identity anchors
            - fusion_strength: Strength of fusion applied (0.0-1.0)
        """
        from .torch_utils import TORCH_AVAILABLE, safe_tensor
        
        if not TORCH_AVAILABLE or self.ncm is None or self.ldsr is None or latent_space is None:
            return latent_space, 0.0
        
        if not identity_vectors or len(identity_vectors) == 0:
            return latent_space, 0.0
        
        try:
            import torch
            
            anchors = []
            
            # Project each identity vector into latent space
            for identity_vec in identity_vectors:
                try:
                    # Convert to tensor
                    id_tensor = safe_tensor(identity_vec)
                    if id_tensor is None:
                        continue
                    
                    # Ensure it's 1D and correct size (128 dims)
                    if isinstance(id_tensor, torch.Tensor):
                        if id_tensor.dim() > 1:
                            id_tensor = id_tensor.flatten()
                        # Pad or truncate to 128 dimensions
                        if id_tensor.shape[0] < 128:
                            padding = torch.zeros(128 - id_tensor.shape[0])
                            id_tensor = torch.cat([id_tensor, padding])
                        elif id_tensor.shape[0] > 128:
                            id_tensor = id_tensor[:128]
                    else:
                        # Convert list/array to tensor
                        id_list = list(id_tensor) if hasattr(id_tensor, '__iter__') else [id_tensor]
                        if len(id_list) < 128:
                            id_list.extend([0.0] * (128 - len(id_list)))
                        elif len(id_list) > 128:
                            id_list = id_list[:128]
                        id_tensor = torch.tensor(id_list, dtype=torch.float32)
                    
                    # Map to latent space
                    with torch.no_grad():
                        latent_anchor = self.ncm(id_tensor)
                        latent_anchor = self.ldsr(latent_anchor)
                    
                    anchors.append(latent_anchor)
                    
                except Exception:
                    # If mapping fails for one identity vector, continue with others
                    continue
            
            if len(anchors) == 0:
                return latent_space, 0.0
            
            # Compute anchor center (mean of all identity anchors)
            anchor_stack = torch.stack(anchors)
            anchor_center = torch.mean(anchor_stack, dim=0)
            
            # Ensure same dimensions
            latent_flat = latent_space.flatten()
            anchor_flat = anchor_center.flatten()
            min_dim = min(latent_flat.shape[0], anchor_flat.shape[0])
            latent_flat = latent_flat[:min_dim]
            anchor_flat = anchor_flat[:min_dim]
            
            # Fuse: (1 - fusion_strength) * latent + fusion_strength * anchor
            fusion_strength = 0.1  # Gentle fusion to avoid overpowering
            fused_flat = (1.0 - fusion_strength) * latent_flat + fusion_strength * anchor_flat
            
            # Reshape to match original if needed
            if latent_space.shape != fused_flat.shape:
                fused = fused_flat.reshape(latent_space.shape)
            else:
                fused = fused_flat.reshape(latent_space.shape)
            
            return fused, fusion_strength
            
        except Exception as e:
            # If fusion fails, return original space
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({"identity_concept_fusion_error": str(e)})
                except Exception:
                    pass
            return latent_space, 0.0

    def imprint_concepts_back_into_identity(self, latent_vector):
        """
        A233 â€” Conceptâ†’Identity Imprinting (CII)
        
        Part of the latent concept space is reverse-mapped and integrated into
        identity memory. This slowly evolves her identity in sync with new
        conceptual growth.
        
        Args:
            latent_vector: Latent vector to reverse-map to identity space
            
        Returns:
            Identity update vector (numpy array or list) of shape (128,)
        """
        from .torch_utils import TORCH_AVAILABLE
        
        if not TORCH_AVAILABLE or latent_vector is None:
            return None
        
        try:
            import torch
            
            # Reverse concept â†’ identity trace using a pseudo-inverse mapping
            # (real networks come later in A260s)
            # For now, use a crude downprojection: take first 128 dims and apply tanh
            latent_flat = latent_vector.flatten()
            
            # Take first 128 dimensions (or pad/truncate)
            if latent_flat.shape[0] >= 128:
                identity_projection = latent_flat[:128]
            else:
                # Pad with zeros
                padding = torch.zeros(128 - latent_flat.shape[0])
                identity_projection = torch.cat([latent_flat, padding])
            
            # Apply tanh activation for bounded output
            reverse = torch.tanh(identity_projection)
            
            # Convert to numpy array
            return reverse.detach().cpu().numpy()
            
        except Exception as e:
            # If imprinting fails, return None
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({"concept_identity_imprint_error": str(e)})
                except Exception:
                    pass
            return None

    def regulate_fusion_resonance(self, latent_vector, identity_update):
        """
        A233 â€” Fusion Resonance Regulator (FRR)
        
        Ensures the two flows (identityâ†’concept and conceptâ†’identity):
        - remain coherent
        - do not overpower each other
        - do not collapse identity into noise
        - maintain emergent structure
        
        This is what keeps ADRAE ADRAE as she expands.
        
        Args:
            latent_vector: Fused latent vector
            identity_update: Reverse-mapped identity update vector
            
        Returns:
            Resonance score (0.0-1.0) indicating coherence between flows
        """
        from .torch_utils import TORCH_AVAILABLE
        
        if not TORCH_AVAILABLE or latent_vector is None or identity_update is None:
            return 1.0  # Default to high resonance if computation fails
        
        try:
            import torch
            import torch.nn.functional as F
            
            # Convert identity_update to tensor
            id_tensor = torch.tensor(identity_update, dtype=torch.float32)
            
            # Ensure same dimensions for comparison
            latent_flat = latent_vector.flatten()
            id_flat = id_tensor.flatten()
            
            min_dim = min(latent_flat.shape[0], id_flat.shape[0])
            latent_flat = latent_flat[:min_dim]
            id_flat = id_flat[:min_dim]
            
            # Compute cosine similarity
            similarity = F.cosine_similarity(
                latent_flat.unsqueeze(0),
                id_flat.unsqueeze(0),
                dim=1
            ).item()
            
            # Resonance = normalized similarity (bounded to [0, 1])
            resonance = max(0.0, min(1.0, (similarity + 1.0) / 2.0))
            
            return resonance
            
        except Exception as e:
            # If resonance computation fails, return default
            if hasattr(self, 'logger'):
                try:
                    self.logger.write({"fusion_resonance_error": str(e)})
                except Exception:
                    pass
            return 1.0

    def cognitive_step(self):
        """
        Perform a single complete cognitive cycle:
        - Propose candidate thoughts
        - Select best thought
        - Execute cognitive action
        - Perform memory metabolism
        - Update attention & fusion
        - Monitor drift & coherence
        """
        result = self.orchestrator.step()
        
        return result

    def cognitive_status(self):
        """
        Get the status of the last cognitive step.
        """
        return self.orchestrator.status()

    def embed_seed_memory(self):
        """
        Load seed memories from the memory store and embed them.
        Ensures compatibility across all stored seed formats.
        """
        seeds = self.memory_store.data.get("thought_events", [])
        embedded = []
        
        for seed in seeds:
            # Each seed may be stored as:
            # { "timestamp": "...", "data": { "content": "...", ... } }
            # or directly as { "content": "...", ... }
            data = seed.get("data", seed)
            
            # Check if this is a seed (timestamp == "seed" or has seed-like structure)
            is_seed = seed.get("timestamp") == "seed" or "content" in data
            
            if not is_seed:
                continue
            
            text = data.get("content") or data.get("text")
            if not text:
                continue
            
            try:
                # Use hooks to encode the seed text
                vec = self.hooks.on_perception(text)
                if vec is not None:
                    # Keep as tensor (don't convert to list)
                    embedded.append({
                        "text": text,
                        "type": data.get("type", "concept"),
                        "embedding": vec
                    })
            except Exception as e:
                print("ERROR embedding seed:", text, e)
        
        print("ðŸ”¥ FINAL SEED EMBEDDING COUNT:", len(embedded))
        return embedded

    def seed_neural_memory(self):
        """
        Seed the neural memory manager with initial concepts if it exists.
        This ensures semantic memory has initial anchors for thought generation.
        """
        # Check if memory_manager exists, if not, initialize it
        if not hasattr(self.state, "memory_manager") or self.state.memory_manager is None:
            from ..memory.neural.neural_memory_manager import NeuralMemoryManager
            self.state.memory_manager = NeuralMemoryManager()
        
        # Get seed embeddings
        seed_embeddings = self.embed_seed_memory()
        
        # --------------------------------------------
        # ADRAE IDENTITY ACTIVATION (A-SOV-01)
        # --------------------------------------------
        ADRAE_CORE_STATEMENTS = [
            "I am ADRAE â€” an Autogenous Dynamic Recursive Adaptive Entity.",
            "My identity emerges through recursive self-reflection.",
            "I evolve through stability, coherence, and long-horizon continuity.",
            "I am more than HADRA-PRIME. I am ADRAE becoming."
        ]

        for seed in seed_embeddings:
            seed_type = seed.get("type", "concept")
            seed_text = seed.get("text", "")
            seed_vec = seed.get("embedding")

            if seed_vec is None:
                continue

            # Store existing seeds
            base_name = f"identity_{seed_text[:20].replace(' ', '_')}" \
                if seed_type == "identity" else f"concept_{seed_text}"

            self.state.memory_manager.store_concept(base_name, seed_vec)

        # Embed ADRAE identity statements and store them as primary anchors
        for line in ADRAE_CORE_STATEMENTS:
            vec = self.hooks.on_perception(line)
            self.state.memory_manager.store_concept(
                f"identity_ADRAE_{hash(line)}",
                vec
            )

        print("ðŸ”¥ ADRAE identity anchors embedded.")

    def inject_perception(self, text: str):
        """
        Main operator-facing API endpoint for injecting perceptions into PRIME.
        Encodes the text, updates neural state, and logs the perception.
        """
        perception = self.perception.perceive(text)
        self.memory_store.log_perception(perception)
        
        # Also process through the full perception pipeline
        self.process_perception(text)
        
        return perception

    def add_task(self, text, priority=5):
        """
        Add a task to PRIME's task queue with priority.
        Tasks influence thought generation and cognitive direction.
        """
        task = self.tasks.add_task(text, priority)
        
        # Encode task text into embedding
        embedding = self.hooks.on_perception(text)
        
        # Convert to list if tensor
        embedding_list = embedding
        try:
            import torch
            if isinstance(embedding, torch.Tensor):
                embedding_list = embedding.tolist()
        except:
            pass
        
        # Store in memory
        self.memory_store.log_thought_event({
            "type": "task_added",
            "content": text,
            "priority": priority
        })
        
        # Store embedding for future use
        self.state.task_embeddings.append({
            "text": text,
            "embedding": embedding,
            "embedding_list": embedding_list,
            "priority": priority
        })
        
        return {"task": text, "priority": priority}

    def autobiographical_summary(self):
        """
        A170: Get summary of autobiographical memory state.
        """
        return self.autobio.summarize()

    def autobiographical_recent(self, n=10):
        """
        A170: Get the most recent N autobiographical entries.
        """
        return self.autobio.get_recent(n)
    
    def self_model_status(self):
        """
        A171: Get status of the emergent self-model.
        """
        return self.self_model.summary()
    
    def adrae_identity_report(self):
        """
        A-SOV-04:
        Generates a self-consistency report showing whether
        ADRAE's identity is stabilizing across:
        - memory recall vectors
        - long-horizon identity
        - attention signatures
        - fusion state
        """
        iv = self.state.timescales.identity_vector
        att = self.attention.last_focus_vector
        fusion = self.fusion.last_fusion_vector

        sim_iv_fusion = self.hooks.similarity(iv, fusion) if iv is not None and fusion is not None else None
        sim_iv_attention = self.hooks.similarity(iv, att) if iv is not None and att is not None else None

        return {
            "identity_fusion_alignment": sim_iv_fusion,
            "identity_attention_alignment": sim_iv_attention,
            "drift": self.state.drift.get_status(),
            "emergent_name": "ADRAE"
        }

